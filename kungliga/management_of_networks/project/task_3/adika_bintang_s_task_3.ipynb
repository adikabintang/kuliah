{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task III - Estimating SLA Conformance and Violation from Device Statistics\n",
    "\n",
    "## 1. Model Training - use Logistic Regression to train a classifier C with the training set. Provide the coefficients (Θ 0 , ..., Θ 12 ) of your model C. (Θ 0 is the offset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 The coefficient for runq-sz is -0.026\n",
      "2 The coefficient for %%memused is 0.032\n",
      "3 The coefficient for proc/s is -0.006\n",
      "4 The coefficient for cswch/s is -0.0\n",
      "5 The coefficient for all_%%usr is -0.001\n",
      "6 The coefficient for ldavg-1 is -0.0\n",
      "7 The coefficient for totsck is 0.01\n",
      "8 The coefficient for pgfree/s is -0.0\n",
      "9 The coefficient for plist-sz is -0.005\n",
      "10 The coefficient for file-nr is 0.001\n",
      "11 The coefficient for idel/s is 0.0\n",
      "12 The coefficient for tps is 0.006\n",
      "The intercept for our model is (teta 0) 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = pd.read_csv('data/X.csv')\n",
    "Y = pd.read_csv('data/Y.csv')\n",
    "Y['TimeStamp'] = Y.TimeStamp.astype(int)\n",
    "\n",
    "X.index = pd.to_datetime(\n",
    "    X['TimeStamp'], unit='s')\n",
    "Y.index = pd.to_datetime(\n",
    "    Y['TimeStamp'], unit='s')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7)\n",
    "\n",
    "# minimum dispframes in SLA: 18 frames/sec\n",
    "min_disp_frames = 18.0\n",
    "\n",
    "# Labeling the y_training\n",
    "y_train_sla_label = np.array(\n",
    "    y_train['DispFrames'] >= min_disp_frames).astype(int)\n",
    "\n",
    "logisticRegr = LogisticRegression(C=1e5, solver='lbfgs', \n",
    "    multi_class='multinomial')\n",
    "\n",
    "X_train = X_train.drop(['TimeStamp'], axis=1)\n",
    "logisticRegr.fit(X_train, y_train_sla_label)\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"{} The coefficient for {} is {}\".format(idx+1, col_name,\n",
    "                                                   np.round(logisticRegr.coef_[0][idx], decimals=3)))\n",
    "\n",
    "intercept = np.round(logisticRegr.intercept_[0], decimals=3)\n",
    "print(\"The intercept for our model is (teta 0) {}\".format(intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accuracy of the Classifiers C - Compute the classification error (ERR) on the test set for C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR of logistic regression: 0.17129629629629628\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# classify\n",
    "prediction_result = logisticRegr.predict(X_test.drop(['TimeStamp'], axis=1))\n",
    "y_test_merged = y_test.copy()\n",
    "y_test_merged['predicted_sla'] = np.array(prediction_result)\n",
    "\n",
    "# compute the confusion matrix, which includes the four numbers \n",
    "# True Positives (TP), True Negatives (TN), False Positives (FN), \n",
    "# and False Negatives (FN)\n",
    "def compute_err(y_test_merged):\n",
    "    arr = []\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    for idx, row in y_test_merged.iterrows():\n",
    "        if row['predicted_sla'] == 1:\n",
    "            if row['DispFrames'] >= min_disp_frames:\n",
    "                TP += 1\n",
    "                arr.append('TP')\n",
    "            else:\n",
    "                #FP += 1\n",
    "                arr.append('FP')\n",
    "        else:\n",
    "            if row['DispFrames'] < min_disp_frames:\n",
    "                TN += 1\n",
    "                arr.append('TN')\n",
    "            else:\n",
    "                #FN += 1\n",
    "                arr.append('FN')\n",
    "\n",
    "    y_test_merged['classification_error'] = np.array(arr)\n",
    "\n",
    "    # compute the classification error\n",
    "    err = 1 - (TP + TN) / len(y_test_merged.index)\n",
    "    return err\n",
    "\n",
    "print(\"ERR of logistic regression: {}\".format(compute_err(y_test_merged)))\n",
    "\n",
    "# example of plotting confusion map was taken from here:\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    \n",
    "    classes = classes[unique_labels(y_true.astype(int), y_pred.astype(int))]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            y_label_pos = i - 0.25 if i == 1 else i + 0.25\n",
    "            ax.text(j, y_label_pos, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "# 1 if pass SLA\n",
    "# 0 if not pass SLA\n",
    "y_true = [ 1 if row['DispFrames'] >= min_disp_frames else 0 \n",
    "          for idx, row in y_test_merged.iterrows() ]\n",
    "class_names = np.array([0, 1]).astype(int)\n",
    "cm = confusion_matrix(y_true, prediction_result)\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(np.array(y_true), prediction_result, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "This model, which is based on logistic regression, has classification error rate of 0.17129.\n",
    "\n",
    "The confusion matrix summarizes how successful the model is in classifying the data. \n",
    "\n",
    "The left-top element of the matrix has value 0 for both true label and predicted label. This is \"true negative\", i.e., the model successfully label the data as \"false\", and the real data is also \"false\". \n",
    "\n",
    "The right-top element of the matrix has 0 on true label, but 1 on predicted label. This is \"false positive\", i.e., the model predicts the value as true, yet the real data says it is false.\n",
    "\n",
    "The bottom-left element of the matrix has value 1 for the true label and 0 for predicted label. This is \"false negative\", i.e, the model predicts the value as false, yet the real data says it is true.\n",
    "\n",
    "The bottom-right element of the matrix has value 1 for both true label and predicted label. This is \"true positive\", i.e., the model successfully predicts the value as true, and the real data is also true.\n",
    "\n",
    "This confusion matrix shows that our logistic-based regression model can predict \"false\"/SLA violation correctly 416 times, and 132 times wrongly predict. It also shows that it is successfully predict \"true\"/passed SLA 479 times and 53 times has mistaken the prediction. These values (also the color; the darker the higher the value is) shows that the model is quite successful in predicting/classifying the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. As a baseline for C, use a naı̈ve method which relies on Y values only. For each x ∈ X, the naı̈ve classifier predicts a value T rue with probability p and F alse with probability 1 − p. Compute p on the training set and the classification error for the naı̈ve classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sla_conform: 1389\n",
      "all: 2520\n",
      "p: 0.5511904761904762\n",
      "ERR of naive classification: 0.44907407407407407\n"
     ]
    }
   ],
   "source": [
    "# p is the fraction of Y values that conform with the SLA\n",
    "sla_conform = len(y_train[y_train['DispFrames'] >= 18.0].index)\n",
    "print(\"sla_conform: {}\".format(sla_conform))\n",
    "print(\"all: {}\".format(len(y_train.index)))\n",
    "p = sla_conform / len(y_train.index)\n",
    "print(\"p: {}\".format(p))\n",
    "\n",
    "# calculating classification error for the naı̈ve classifier\n",
    "sla_pass_prediction = int(p * len(y_test.index))\n",
    "sla_not_pass_prediction = len(y_test.index) - sla_pass_prediction\n",
    "sla_pass_real = y_test[y_test['DispFrames'] < min_disp_frames]['DispFrames'].count()\n",
    "sla_not_pass_real = len(y_test.index) - sla_pass_real\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "if sla_pass_prediction > sla_pass_real:\n",
    "    tp = sla_pass_real\n",
    "else:\n",
    "    tp = sla_pass_real - sla_pass_prediction \n",
    "\n",
    "if sla_not_pass_prediction > sla_not_pass_real:\n",
    "    tn = sla_not_pass_real\n",
    "else:\n",
    "    tn = sla_not_pass_real - sla_not_pass_prediction \n",
    "\n",
    "#print(\"sla_pred: {}\\nsla_pass_rea = {}\\ntp: {}\\n\".format(sla_pass_prediction, sla_pass_real, tp))\n",
    "#print(\"not_sla_pred: {}\\not_sla_pass_rea = {}\\ntn: {}\\n\".format(sla_not_pass_prediction, sla_not_pass_real, tn))\n",
    "\n",
    "# err = 1 - (tp+tn)/m\n",
    "naive_err = 1 - (tp + tn) / len(y_test.index)\n",
    "print(\"ERR of naive classification: {}\".format(naive_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build a new classifier by extending the linear regression function developed in Task II with a check on the output, i.e., the Video Frame Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR of linear regression-based model: 0.17222222222222228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train.drop(['TimeStamp'], axis=1))\n",
    "\n",
    "# predict with linear regression\n",
    "y_predict_linear_reg = regression_model.predict(X_test.drop(['TimeStamp'], axis=1))\n",
    "\n",
    "# then, the model built by linear regression is used to classify the SLA based on \n",
    "# Y values\n",
    "prediction_result_linear_reg = np.array(\n",
    "    np.where(y_predict_linear_reg >= min_disp_frames, 1, 0)).flatten()\n",
    "\n",
    "# classification error for this new classifier on the test set\n",
    "y_test_merged_w_linear_reg = y_test.copy()\n",
    "y_test_merged_w_linear_reg['predicted_sla'] = np.array(prediction_result_linear_reg)\n",
    "linear_reg_err = compute_err(y_test_merged_w_linear_reg)\n",
    "print(\"ERR of linear regression-based model: {}\".format(linear_reg_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The comparison of the classification errors of the models\n",
    "\n",
    "We have three models and their classification error values:\n",
    "\n",
    "- Logistic regression-based model's error: 0.17129\n",
    "- Naive (y values-only) error: 0.44907\n",
    "- Linear regression (and extended)-based model's error: 0.17222\n",
    "\n",
    "The classification error describes how reliable the model is. The higher the error value is, the less reliable the model will be. If we sort the error in increasing order, the sequence is as follows: logistic regression-based model, linear regression-based model, naive model. We can conclude that logistic regression-based and linear regression-based is quite reliable, but the naive model is not that reliable.\n",
    "\n",
    "The reason why the errors differ lies on how the model is build. The naive error only relies on the probability of y=1. The probability is taken from the training set. This is not reliable because of 2 reasons: the training set and the test set might not be evenly distributed and it does not take any x values into consideration.\n",
    "\n",
    "On the other hand, the regression model, both logistic and linear, takes x values into consideration. Most importantly, it tries to minimize the cost function when building the model (finding the coefficients) in order to be as precise as possible. This makes the regression-based models much reliable (i.e., smaller classification errors) than the naive model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
